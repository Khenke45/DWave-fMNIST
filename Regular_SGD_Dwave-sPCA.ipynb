{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dwave_sapi2\n",
    "from dwave_sapi2.local import local_connection\n",
    "from dwave_sapi2.remote import RemoteConnection\n",
    "from dwave_sapi2.core import async_solve_ising, await_completion, solve_ising\n",
    "from dwave_sapi2.util import get_hardware_adjacency, qubo_to_ising\n",
    "from dwave_sapi2.embedding import find_embedding, embed_problem, unembed_answer\n",
    "import time\n",
    "import dwave_sapi2.remote\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import math \n",
    "import random\n",
    "from numpy import linalg as LA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DW_2000Q_2_1', 'DW_2000Q_5', 'DW_2000Q_VFYC_2_1', 'c4-sw_optimize', 'DW_2000Q_VFYC_5', 'c4-sw_sample']\n"
     ]
    }
   ],
   "source": [
    "conn = dwave_sapi2.remote.RemoteConnection('https://cloud.dwavesys.com/sapi','lanl-871046202c27322e8450da36b7b35653c94c1115')\n",
    "print conn.solver_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/LANL/AFRL-DISC Data/Blackbox brief for LANL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sPCA= pd.read_csv('sPCA_32.csv', sep=',', encoding = 'utf8')\n",
    "data = sPCA.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('Fashion_Downsampled_4Bit.mat')\n",
    "Down_Sampled_4bit = mat['Down_Sampled_4bit']\n",
    "data = Down_Sampled_4bit.reshape(len(Down_Sampled_4bit),len(Down_Sampled_4bit[0])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(np.float32)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data\n",
    "for i in range(len(data)):\n",
    "\n",
    "    data[i]=data[i]/LA.norm(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss(I,Phi,sparse_representation_coefficients,lam):\n",
    "    Energy = .5*LA.norm(I-np.dot(Phi,sparse_representation_coefficients))**2 +lam*np.count_nonzero(sparse_representation_coefficients)\n",
    "    return Energy\n",
    "\n",
    "def reconstruction_loss(I,Phi,sparse_representation_coefficients):\n",
    "    Loss = LA.norm(I-np.dot(Phi,sparse_representation_coefficients))**2\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Random Phi Matrix\n",
    "Neurons = 32\n",
    "RandomTrainingSample_Index = random.sample(range(len(data)),Neurons)\n",
    "Rand_Features = data[RandomTrainingSample_Index,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000596\n",
      "1.0000000596\n",
      "0.999999940395\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.999999970198\n",
      "1.0000000596\n",
      "0.999999940395\n",
      "1.0000000596\n",
      "1.0\n",
      "1.0\n",
      "0.999999880791\n",
      "1.0\n",
      "0.999999850988\n",
      "1.00000011921\n",
      "1.0\n",
      "1.0\n",
      "0.999999970198\n",
      "1.0000000596\n",
      "1.0\n",
      "1.0\n",
      "0.999999970198\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000596\n",
      "1.0000000596\n",
      "1.0\n",
      "1.0\n",
      "0.999999970198\n",
      "1.0000000596\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.999999940395\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000596\n",
      "1.0000000596\n",
      "0.999999940395\n",
      "1.0\n",
      "1.0000000596\n",
      "1.0000000596\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0000000596\n",
      "1.0000000596\n",
      "0.999999940395\n",
      "1.00000011921\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#Normalize Phi\n",
    "Phi = Rand_Features.T\n",
    "Phi = np.asmatrix(Phi)\n",
    "\n",
    "for i in range(Neurons):\n",
    "    print((math.sqrt(Phi[:,i].T*Phi[:,i])))\n",
    "    Phi[:,i]= Phi[:,i]/(math.sqrt(Phi[:,i].T*Phi[:,i]))\n",
    "    print((math.sqrt(Phi[:,i].T*Phi[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat('Phi_Random_Lambda_.45_RSGD_sPCA.mat', {'Phi':Phi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull Random images for SGD Training\n",
    "Num_Ran_Sam =10000 \n",
    "RandomTrainingSample_Index = random.sample(range(len(data)),Num_Ran_Sam)\n",
    "Data_Patches = data[RandomTrainingSample_Index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = .5*np.dot(np.squeeze(Phi.T),np.squeeze(Phi))\n",
    "lam = .45\n",
    "lam_vector = np.full((len(Phi.T), 1), lam, dtype=np.float)\n",
    "h_vector = np.add(-np.dot(Phi.T,Data_Patches[0,:].T),np.squeeze(np.add(lam_vector,np.full((len(Phi.T), 1), lam, dtype=np.float))))\n",
    "h_vector = np.squeeze(np.asarray(h_vector))\n",
    "#Replace Diagonal of Q with corresponding h values    \n",
    "for i in range(0,len(Q)):\n",
    "    Q[i,i]=h_vector[i]\n",
    "\n",
    "#Create Dictionary of Upper Triangle part of Q with Diagonal Elements\n",
    "QDictionary ={}\n",
    "for i in range(0,len(Q)):\n",
    "    for j in range(i,len(Q)):\n",
    "            QDictionary[(i,j)] = Q[i,j]\n",
    "            #print(i,j,Q[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32L,)\n",
      "component 0, try 0:\n",
      "max overfill = 2, num max overfills = 10\n",
      "max overfill = 1, num max overfills = 453\n",
      "max overfill = 1, num max overfills = 453\n",
      "Embedding found. Minimizing chains...\n",
      "max chain size = 19, num max chains = 2, qubits used = 453\n",
      "max chain size = 19, num max chains = 1, qubits used = 462\n",
      "max chain size = 19, num max chains = 1, qubits used = 462\n",
      "max chain size = 17, num max chains = 4, qubits used = 411\n",
      "max chain size = 17, num max chains = 3, qubits used = 402\n",
      "max chain size = 17, num max chains = 3, qubits used = 402\n",
      "elapsed time: 9.62599992752\n",
      "Usage: \n",
      "(32L,)\n",
      "component 0, try 0:\n",
      "max overfill = 2, num max overfills = 8\n",
      "max overfill = 1, num max overfills = 418\n",
      "max overfill = 1, num max overfills = 418\n",
      "max overfill = 1, num max overfills = 401\n",
      "max overfill = 1, num max overfills = 401\n",
      "Embedding found. Minimizing chains...\n",
      "max chain size = 16, num max chains = 2, qubits used = 401\n",
      "max chain size = 16, num max chains = 1, qubits used = 399\n",
      "max chain size = 16, num max chains = 1, qubits used = 399\n",
      "max chain size = 16, num max chains = 1, qubits used = 383\n",
      "max chain size = 16, num max chains = 1, qubits used = 383\n",
      "elapsed time: 5.5680000782\n",
      "Usage: \n",
      "(32L,)\n",
      "component 0, try 0:\n",
      "max overfill = 2, num max overfills = 22\n",
      "max overfill = 2, num max overfills = 1\n",
      "max overfill = 2, num max overfills = 1\n",
      "max overfill = 1, num max overfills = 460\n",
      "max overfill = 1, num max overfills = 429\n",
      "max overfill = 1, num max overfills = 425\n",
      "max overfill = 1, num max overfills = 425\n",
      "max overfill = 1, num max overfills = 420\n",
      "max overfill = 1, num max overfills = 421\n",
      "max overfill = 1, num max overfills = 421\n",
      "Embedding found. Minimizing chains...\n",
      "max chain size = 21, num max chains = 2, qubits used = 421\n",
      "max chain size = 20, num max chains = 1, qubits used = 422\n",
      "max chain size = 18, num max chains = 1, qubits used = 420\n",
      "max chain size = 18, num max chains = 1, qubits used = 420\n",
      "elapsed time: 6.96199989319\n",
      "Usage: \n",
      "(32L,)\n",
      "component 0, try 0:\n",
      "max overfill = 2, num max overfills = 22\n",
      "max overfill = 1, num max overfills = 473\n",
      "max overfill = 1, num max overfills = 453\n",
      "max overfill = 1, num max overfills = 425\n",
      "max overfill = 1, num max overfills = 425\n",
      "Embedding found. Minimizing chains...\n",
      "max chain size = 20, num max chains = 1, qubits used = 425\n",
      "max chain size = 17, num max chains = 2, qubits used = 415\n",
      "max chain size = 16, num max chains = 9, qubits used = 422\n",
      "max chain size = 16, num max chains = 9, qubits used = 422\n",
      "elapsed time: 4.98799991608\n",
      "Usage: \n",
      "(32L,)\n",
      "component 0, try 0:\n",
      "max overfill = 2, num max overfills = 45\n",
      "max overfill = 2, num max overfills = 7\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "shuffling variables...\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 3\n",
      "shuffling variables...\n",
      "max overfill = 2, num max overfills = 3\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "shuffling variables...\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "shuffling variables...\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "max overfill = 2, num max overfills = 2\n",
      "component 0, try 1:\n",
      "max overfill = 2, num max overfills = 21\n",
      "max overfill = 1, num max overfills = 409\n",
      "max overfill = 1, num max overfills = 405\n",
      "max overfill = 1, num max overfills = 405\n",
      "Embedding found. Minimizing chains...\n",
      "max chain size = 20, num max chains = 1, qubits used = 405\n",
      "max chain size = 19, num max chains = 1, qubits used = 402\n",
      "max chain size = 17, num max chains = 4, qubits used = 418\n",
      "max chain size = 17, num max chains = 1, qubits used = 438\n",
      "max chain size = 17, num max chains = 1, qubits used = 438\n",
      "elapsed time: 30.1860001087\n",
      "Usage: \n"
     ]
    }
   ],
   "source": [
    "#Finding lowest Energy Embedding    \n",
    "Embedding_Trials = 5\n",
    "Unembedded_Solutions=[]\n",
    "Embeddings =[]\n",
    "EmbeddingTime=[]\n",
    "J0 =[]\n",
    "JC=[]\n",
    "Coefficients_sol =[]\n",
    "Coefficients_embsol=[]\n",
    "solver = conn.get_solver('DW_2000Q_2_1') \n",
    "A = get_hardware_adjacency(solver)\n",
    "\n",
    "\n",
    "for i in range(Embedding_Trials):\n",
    "    \n",
    "        (h_, J_, ising_offset) = qubo_to_ising(QDictionary)\n",
    "        print(np.asarray(h_).shape)\n",
    "        #[h_,J_, offsetarg]= qubo_to_ising[Q]\n",
    "\n",
    "        #solver = local_connection.get_solver(\"c4-sw_optimize\") # dont select\n",
    "\n",
    "\n",
    "        # find and print embeddings for problem graph\n",
    "        t = time.time()\n",
    "\n",
    "        embeddings = find_embedding(J_, A, verbose=1)\n",
    "        elapsed = time.time() - t\n",
    "        EmbeddingTime.append(elapsed)\n",
    "        print \"elapsed time:\", elapsed\n",
    "        #print \"embeddings are: \", embeddings\n",
    "        Embeddings.append(embeddings)\n",
    "\n",
    "        # embed the problem into solver graph\n",
    "        (h0, j0, jc, new_emb) = embed_problem(h_, J_, embeddings, A) #update to have multiple solutions and save embeddings\n",
    "#         print \"embedded problem result:\\nj0: \", j0\n",
    "#         print \"jc: \", jc\n",
    "        J0.append(j0)\n",
    "        JC.append(jc)\n",
    "\n",
    "        # find unembedded results for chain strengths -0.5, -1.0, -2.0\n",
    "\n",
    "        Solutions =[]\n",
    "        Answers=[]\n",
    "        for chain_strength in (-0.5, -1.0, -2.0):\n",
    "                # set chain strength values\n",
    "            jc = dict.fromkeys(jc, chain_strength)\n",
    "\n",
    "            # create new J array concatenating j0 with jc\n",
    "            emb_j = j0.copy()\n",
    "            emb_j.update(jc)\n",
    "\n",
    "                # solve embedded problem\n",
    "\n",
    "            answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "            Answers.append(answer['energies'])\n",
    "\n",
    "                # unembed and print result of the form:\n",
    "                # solution [solution #]\n",
    "                # var [var #] : [var value] ([qubit index] : [original qubit value] ...)\n",
    "            result = unembed_answer(answer['solutions'], new_emb, broken_chains=\"minimize_energy\", h=h_, j=J_)\n",
    "            Solutions.append(result)\n",
    "            #Solutions.append(result['energies']) DOESNT HAVE energies AS AN OUTPUT\n",
    "\n",
    "#             print(result)\n",
    "#             print \"result for chain strength = \", chain_strength\n",
    "#             for i, (embsol, sol) in enumerate(zip(answer['solutions'], result)):\n",
    "#                 print \"solution\", i\n",
    "#                 #save solution coefficients\n",
    "#                 for j, emb in enumerate(embeddings):\n",
    "#                     Coefficients_sol.append(sol[j])\n",
    "#                     print \"var %d: %d (\" % (j, sol[j]),\n",
    "#                     for k in emb:\n",
    "#                         Coefficients_embsol.append(embsol[k])\n",
    "#                         print \"%d:%d\" % (k, embsol[k]),\n",
    "#                     print \")\"\n",
    "            #print \"Solutions\", Solutions\n",
    "        New_Solutions=[]\n",
    "        #Convert to {0,1}\n",
    "        for j in range(0,3):\n",
    "            x = np.asarray(Solutions[j][0])\n",
    "            for i in range(0,len(x)):\n",
    "                if x[i] == -1:\n",
    "                     x[i] = 0\n",
    "            New_Solutions.append(x)\n",
    "        Unembedded_Solutions.append(New_Solutions)\n",
    "        if __name__ == \"__main__\":\n",
    "            if len(sys.argv) == 1:\n",
    "                embedding_example()\n",
    "            else:\n",
    "                print \"Usage: \"\n",
    "                #print \"%s: Find embedding for k_6 structured graph, embed problem, solve problem, unembed answer\" % sys.argv[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Energies = []\n",
    "for i in range(len(Unembedded_Solutions)):\n",
    "    Energy_Chain = []\n",
    "    for j in range(3):\n",
    "        Energy_Chain.append(sparse_loss(Data_Patches[0],Phi,np.asmatrix(Unembedded_Solutions[i][j]).T,lam))\n",
    "    index_min = np.argmin(np.asarray(Energy_Chain))\n",
    "    All_Energies.append(Energy_Chain[index_min])\n",
    "index_min = np.argmin(np.asarray(All_Energies))\n",
    "embeddings = Embeddings[index_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Image Found', 0)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "('Image Found', 10)\n",
      "('Image Found', 20)\n",
      "('Image Found', 30)\n",
      "('Image Found', 40)\n",
      "('Image Found', 50)\n",
      "('Image Found', 60)\n",
      "('Image Found', 70)\n",
      "('Image Found', 80)\n",
      "('Image Found', 90)\n",
      "('Image Found', 100)\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "('Image Found', 110)\n",
      "('Image Found', 120)\n",
      "('Image Found', 130)\n",
      "('Image Found', 140)\n",
      "('Image Found', 150)\n",
      "('Image Found', 160)\n",
      "('Image Found', 170)\n",
      "('Image Found', 180)\n",
      "('Image Found', 190)\n",
      "('Image Found', 200)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "('Image Found', 210)\n",
      "('Image Found', 220)\n"
     ]
    }
   ],
   "source": [
    "#SGD Loop to update Dictionary\n",
    "\n",
    "mini_batch_size = 1000\n",
    "tol = 10**(-32)\n",
    "max_iterations = 10000\n",
    "eta =.005 #Learning Rate\n",
    "lam = .35\n",
    "lam_vector = np.full((len(Phi.T), 1), lam, dtype=np.float)\n",
    "count = 0\n",
    "Previous_Gradient = 0\n",
    "momentum_term = .2\n",
    "\n",
    "#Energy_Min = 20\n",
    "\n",
    "\n",
    "#Total_Energies = []\n",
    "\n",
    "solver = conn.get_solver('DW_2000Q_2_1') \n",
    "A = get_hardware_adjacency(solver)\n",
    "#Non_Zero_Coefficients =[]\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    \n",
    "        \n",
    "    #Random Draw from Data\n",
    "    Indexing = random.sample(range(len(Data_Patches)), mini_batch_size)\n",
    "    \n",
    "    Neuron_Activation =[]\n",
    "    Gradients =[]\n",
    "    Unembedded_Solutions_Training= []\n",
    "    t1 = time.time()\n",
    "    New_Solutions = []\n",
    "    Temp_Data_Patches=[]\n",
    "    Q = .5*np.dot(np.squeeze(Phi.T),np.squeeze(Phi))\n",
    "    \n",
    "\n",
    "    J0 =[]\n",
    "    JC=[]\n",
    "    Coefficients_sol =[]\n",
    "    Coefficients_embsol=[]\n",
    "    image_number = 0\n",
    "    for sample in Indexing:\n",
    "        \n",
    "        h_vector = np.add(-np.dot(Phi.T,Data_Patches[sample,:].T),np.squeeze(np.add(lam_vector,np.full((len(Phi.T), 1), lam, dtype=np.float))))\n",
    "        h_vector = np.squeeze(np.asarray(h_vector))\n",
    "        #Replace Diagonal of Q with corresponding h values    \n",
    "        for i in range(0,len(Q)):\n",
    "            Q[i,i]=h_vector[i]\n",
    "\n",
    "        #Create Dictionary of Upper Triangle part of Q with Diagonal Elements\n",
    "        QDictionary ={}\n",
    "        for i in range(0,len(Q)):\n",
    "            for j in range(i,len(Q)):\n",
    "                    QDictionary[(i,j)] = Q[i,j]\n",
    "                    #print(i,j,Q[i,j])\n",
    "\n",
    "        (h_, J_, ising_offset) = qubo_to_ising(QDictionary)\n",
    "            #[h_,J_, offsetarg]= qubo_to_ising[Q]\n",
    "\n",
    "#         embeddings = find_embedding(J_, A, verbose=1)\n",
    "        (h0, j0, jc, new_emb) = embed_problem(h_, J_, embeddings, A)\n",
    "\n",
    "        Solutions =[]\n",
    "        Answers=[]\n",
    "        \n",
    "        Temp_Data_Patches.append(Data_Patches[sample,:].T)\n",
    "\n",
    "            # solve embedded problem\n",
    "        \n",
    "        Solutions =[]\n",
    "        Answers=[]\n",
    "        for chain_strength in (-0.5, -1.0, -2.0):\n",
    "                # set chain strength values\n",
    "            jc = dict.fromkeys(jc, chain_strength)\n",
    "\n",
    "            # create new J array concatenating j0 with jc\n",
    "            emb_j = j0.copy()\n",
    "            emb_j.update(jc)\n",
    "\n",
    "                # solve embedded problem\n",
    "            try:\n",
    "                answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                Answers.append(answer['energies'])\n",
    "            except RuntimeError:\n",
    "                time.sleep(30)\n",
    "                print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                try:\n",
    "                    answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                    Answers.append(answer['energies'])\n",
    "\n",
    "                except RuntimeError:\n",
    "                    time.sleep(30)\n",
    "                    print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                    try:\n",
    "                        answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                        Answers.append(answer['energies'])\n",
    "                    except RuntimeError:\n",
    "                        time.sleep(30)\n",
    "                        print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                        try:\n",
    "                            answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                            Answers.append(answer['energies'])\n",
    "\n",
    "                        except RuntimeError:\n",
    "                            time.sleep(30)\n",
    "                            print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                            try:\n",
    "                                answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                Answers.append(answer['energies'])\n",
    "\n",
    "                            except RuntimeError:\n",
    "                                time.sleep(30)\n",
    "                                print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                                try:\n",
    "                                    answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                    Answers.append(answer['energies'])\n",
    "\n",
    "                                except RuntimeError:\n",
    "                                    time.sleep(30)\n",
    "                                    print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                                    try:\n",
    "                                        answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                        Answers.append(answer['energies'])\n",
    "\n",
    "                                    except RuntimeError:\n",
    "                                        time.sleep(30)\n",
    "                                        print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                                        try:\n",
    "                                            answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                            Answers.append(answer['energies'])\n",
    "\n",
    "                                        except RuntimeError:\n",
    "                                            time.sleep(30)\n",
    "                                            print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                                            try:\n",
    "                                                answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                                Answers.append(answer['energies'])\n",
    "\n",
    "                                            except RuntimeError:\n",
    "                                                time.sleep(30)\n",
    "                                                print('Runtime Error: Resubmitting Problem to D-Wave')\n",
    "                                                answer = solve_ising(solver, h0, emb_j, num_reads=10)# save results in an array\n",
    "                                                Answers.append(answer['energies'])\n",
    "\n",
    "\n",
    "\n",
    "                # unembed and print result of the form:\n",
    "                # solution [solution #]\n",
    "                # var [var #] : [var value] ([qubit index] : [original qubit value] ...)\n",
    "            result = unembed_answer(answer['solutions'], new_emb, broken_chains=\"minimize_energy\", h=h_, j=J_)\n",
    "            Solutions.append(result)\n",
    "            #Solutions.append(result['energies']) DOESNT HAVE energies AS AN OUTPUT\n",
    "\n",
    "            #print(result)\n",
    "            #print \"result for chain strength = \", chain_strength\n",
    "            for i, (embsol, sol) in enumerate(zip(answer['solutions'], result)):\n",
    "                #print \"solution\", i\n",
    "                #save solution coefficients\n",
    "                for j, emb in enumerate(embeddings):\n",
    "                    Coefficients_sol.append(sol[j])\n",
    "                    #print \"var %d: %d (\" % (j, sol[j]),\n",
    "                    for k in emb:\n",
    "                        Coefficients_embsol.append(embsol[k])\n",
    "                        #print \"%d:%d\" % (k, embsol[k]),\n",
    "                    #print \")\"\n",
    "            #print \"Solutions\", Solutions\n",
    "        New_Solutions=[]\n",
    "        #Convert to {0,1}\n",
    "        for j in range(0,3):\n",
    "            x = np.asarray(Solutions[j][0])\n",
    "            x = (x+1)/2\n",
    "    #             for i in range(0,Phi.shape[1]):\n",
    "    #                 if x[i] == -1:\n",
    "    #                      x[i] = 0\n",
    "            New_Solutions.append(x)\n",
    "        New_Solutions = np.asarray(New_Solutions)\n",
    "        All_Energies =[]\n",
    "        for k in range(len(New_Solutions)): #Find for each chain strength\n",
    "                #Energy function with 0 norm on lambda\n",
    "                Energy = sparse_loss(Data_Patches[sample],Phi,np.asmatrix(New_Solutions[k]).T,lam)\n",
    "                #print(Energy)\n",
    "                All_Energies.append(Energy)\n",
    "        index_min = np.argmin(np.asarray(All_Energies))\n",
    "        Unembedded_Solutions_Training.append(New_Solutions[index_min])\n",
    "        if image_number%10==0:\n",
    "            print('Image Found', image_number)\n",
    "        if image_number%100==0:\n",
    "            print(New_Solutions[index_min])\n",
    "        image_number+= 1\n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "    Sparse_Rep = np.asarray(Unembedded_Solutions_Training)\n",
    "    Sparse_Rep = np.asmatrix(np.squeeze(np.asarray(Sparse_Rep)))\n",
    "\n",
    "    print('////////////////////////////////Sparse Reps Found\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\')\n",
    "    Non_Zero_Coefficients.append(np.count_nonzero(Sparse_Rep))\n",
    "    print('Non_Zero_Coefficient_Count',np.asarray(Non_Zero_Coefficients))\n",
    "    #Unembedded_Solutions_Training = Sparse_Rep\n",
    "\n",
    "    Temp_Data_Patches =np.asarray(Temp_Data_Patches)\n",
    "    #Regular SGD\n",
    "    Phi_New = Phi\n",
    "    for i in range(mini_batch_size):\n",
    "        error = np.subtract(Temp_Data_Patches[i].T,np.squeeze(np.dot(Phi,Unembedded_Solutions_Training[i].T)))\n",
    "        Gradient = - (eta/mini_batch_size)*np.outer(error,Sparse_Rep[i]) + momentum_term*Previous_Gradient\n",
    "        Phi_New = Phi_New + Gradient\n",
    "        Previous_Gradient = Gradient\n",
    "\n",
    "    #normalize Updated Phi\n",
    "\n",
    "    for i in range(Neurons):\n",
    "    #print((math.sqrt(Phi[:,i].T*Phi[:,i])))\n",
    "        Phi_New[:,i]= Phi_New[:,i]/(math.sqrt(np.dot(Phi_New[:,i].T,Phi_New[:,i])))\n",
    "    #print((math.sqrt(Phi[:,i].T*Phi[:,i])))\n",
    "    if iteration ==0:\n",
    "        Energies =[]\n",
    "        for i in range(mini_batch_size):\n",
    "            Energies.append(sparse_loss(Temp_Data_Patches[i],Phi,Sparse_Rep[i].T,lam))\n",
    "        Energy = np.sum(np.asarray(Energies))/mini_batch_size\n",
    "        Total_Energies.append(Energy)\n",
    "    \n",
    "    Energies =[]\n",
    "    for i in range(mini_batch_size):\n",
    "        Energies.append(sparse_loss(Temp_Data_Patches[i],Phi_New,Sparse_Rep[i].T,lam))\n",
    "    Energy = np.sum(np.asarray(Energies))/mini_batch_size\n",
    "\n",
    "    Total_Energies.append(Energy)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    #print(plt.plot(range(iteration+1), Total_Energies ))\n",
    "    print('Energies,Epoc :', Total_Energies,count)\n",
    "    elapsed1 = time.time() - t1\n",
    "    print(elapsed1)\n",
    "\n",
    "#     if Energy < Energy_Min:\n",
    "        \n",
    "#         Energy_Min = Energy\n",
    "#         #renormalize phi\n",
    "    sio.savemat('Phi_New_Fashion_MiniBatch1000_sPCA_32_Lambda_.1_RSGD_Undercomplete.mat', {'Phi_New':Phi_New})\n",
    "    sio.savemat('TotalEnergies_Fashion_MiniBatch1000_sPCA_32_Lambda_.1_RSGD_Undercomplete.mat', {'Total_Energies':Total_Energies})\n",
    "    if LA.norm(Phi_New-Phi) > tol:\n",
    "        print(LA.norm(Phi_New-Phi))\n",
    "        Phi = Phi_New\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('converged')\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
