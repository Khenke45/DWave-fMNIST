{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import ortho_group\n",
    "from sklearn.svm import SVC \n",
    "import math \n",
    "import random\n",
    "from numpy import linalg as LA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/LANL/AFRL-DISC Data/Blackbox brief for LANL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sPCA= pd.read_csv('sPCA_32.csv', sep=',', encoding = 'utf8')\n",
    "data = sPCA.values\n",
    "#Load sPCA Dictionary from found sPCA components\n",
    "mat = sio.loadmat('sPCA_Phi.mat')\n",
    "sPCA_Phi = mat['sPCA_Phi']\n",
    "\n",
    "mat = sio.loadmat('fMnist_ytrainlabels.mat')\n",
    "y_train = np.squeeze(np.asarray(mat['y_train'].T))\n",
    "mat = sio.loadmat('fMnist_ytestlabels.mat')\n",
    "y_test = np.squeeze(np.asarray(mat['y_test'].T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reconstructed_Data = np.dot(data,sPCA_Phi)\n",
    "Reconstructed_Data = Reconstructed_Data.reshape(len(Reconstructed_Data),28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cutting up image\n",
    "def get_cell(img, x, y):\n",
    "    return img[x:x+span,y:y+span].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patch up data\n",
    "full_set = []\n",
    "row_size = len(Reconstructed_Data[1])\n",
    "col_size = len(Reconstructed_Data[2])\n",
    "\n",
    "span = 7\n",
    "\n",
    "\n",
    "\n",
    "row_size_list = 4\n",
    "col_size_list = 4\n",
    "\n",
    "for i in range(len(Reconstructed_Data)):\n",
    "    cropped_image = Reconstructed_Data[i]\n",
    "    \n",
    "    #normailze image with mean 0 and unit variance\n",
    "    cropped_image = (cropped_image - np.mean(cropped_image)) / (np.std(cropped_image))\n",
    "   \n",
    "    submatrix_list = [get_cell(cropped_image,x,y) for x in range(0,row_size,span) for y in range(0,col_size,span)]\n",
    "    \n",
    "    \n",
    "    d2_list = [submatrix_list[i:i+row_size_list] for i in range(0,len(submatrix_list),row_size_list)]\n",
    "    #Validation of chopping\n",
    "    X = np.zeros((row_size,col_size))\n",
    "    for i in range(row_size_list):\n",
    "        for j in range(col_size_list):\n",
    "            for k in range(span):\n",
    "                for l in range(span):\n",
    "                    X[i*span+k,j*span+l] = d2_list[i][j][k][l]\n",
    "    full_set.append(d2_list)\n",
    "    \n",
    "\n",
    "Data_Patches = []\n",
    "for i in range(len(Reconstructed_Data)):\n",
    "    for j in range(row_size_list):\n",
    "        for k in range(col_size_list):\n",
    "            Sample_image_patch = full_set[i][j][k]\n",
    "            Data_Patches.append(Sample_image_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Patches = np.asarray(Data_Patches)\n",
    "Data_Patches = Data_Patches.reshape(len(Data_Patches),len(Data_Patches[1])*len(Data_Patches[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120000L, 49L)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalize data\n",
    "for i in range(len(Data_Patches)):\n",
    "    if LA.norm(Data_Patches[i])!=0:\n",
    "        Data_Patches[i]=Data_Patches[i]/LA.norm(Data_Patches[i])\n",
    "# Data_Patches= np.asarray(Data_Patches)\n",
    "Data_Patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64L, 49L)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Randomly imprinted Phi Matrix with number of features = # Neurons(qubits)\n",
    "Neurons = 64\n",
    "RandomTrainingSample_Index = random.sample(range(len(Data_Patches)),Neurons)\n",
    "Rand_Features = Data_Patches[RandomTrainingSample_Index,:]\n",
    "Rand_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Features for data phi and Normalize\n",
    "Phi = Rand_Features.T\n",
    "for i in range(Neurons):\n",
    "    Phi[:,i]= Phi[:,i]/(LA.norm(Phi[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss(I,Phi,sparse_representation_coefficients,lam):\n",
    "    Energy = .5*LA.norm(I-np.dot(Phi,sparse_representation_coefficients))**2 +lam*np.count_nonzero(sparse_representation_coefficients)\n",
    "    return Energy\n",
    "\n",
    "def reconstruction_loss(I,Phi,sparse_representation_coefficients):\n",
    "    Loss = LA.norm(I-np.dot(Phi,sparse_representation_coefficients))**2\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(0.17665513314802156, 2.118871576846369, 3072)\n",
      "0.00015013387649002433\n",
      "10\n",
      "(0.1781932672192071, 2.119110030965031, 3072)\n",
      "0.01268547278841093\n",
      "20\n",
      "(0.17320484219549662, 2.1184730973796375, 3072)\n",
      "0.012203322889231824\n",
      "30\n",
      "(0.17132769494502123, 2.1181698523200154, 3072)\n",
      "0.010521190494426068\n",
      "40\n",
      "(0.1655067652890869, 2.1166411376156513, 3072)\n",
      "0.010751956526318038\n",
      "50\n",
      "(0.16453952692804466, 2.1164380094599635, 3072)\n",
      "0.010073019169005264\n",
      "60\n",
      "(0.16815628872711208, 2.1173747992439873, 3072)\n",
      "0.009687315893373011\n",
      "70\n",
      "(0.16261316938324993, 2.1161178079082523, 3072)\n",
      "0.009724845467980801\n",
      "80\n",
      "(0.1560215111132675, 2.1146198309570767, 3072)\n",
      "0.009635895658761592\n",
      "90\n",
      "(0.1673545478855996, 2.116660921740773, 3072)\n",
      "0.008936279068310557\n",
      "100\n",
      "(0.16171540829952621, 2.1152913962205235, 3072)\n",
      "0.008759085986041935\n",
      "110\n",
      "(0.1647535334740342, 2.116625722544411, 3072)\n",
      "0.0083867345850698\n",
      "120\n",
      "(0.1616146748450357, 2.115637982981431, 3072)\n",
      "0.008340465888514798\n",
      "130\n",
      "(0.1627778106776601, 2.116155206861767, 3072)\n",
      "0.007512617042010185\n",
      "140\n",
      "(0.1622392932916959, 2.1161770319792264, 3072)\n",
      "0.00814791675940066\n",
      "150\n",
      "(0.15622158752576962, 2.1149706947488993, 3072)\n",
      "0.008006793626707762\n",
      "160\n",
      "(0.15546370921918573, 2.114503105716005, 3072)\n",
      "0.008083878496071097\n",
      "170\n",
      "(0.1515200599199613, 2.11375228136079, 3072)\n",
      "0.007719252789685058\n",
      "180\n",
      "(0.15854488087346102, 2.1150899473793885, 3072)\n",
      "0.007757750505064175\n",
      "190\n",
      "(0.16014662921189407, 2.1153866271378767, 3072)\n",
      "0.008090868696671877\n",
      "200\n",
      "(0.1607426242394498, 2.1156298252981824, 3072)\n",
      "0.00811677391444293\n",
      "210\n",
      "(0.15532391518278937, 2.114162026021067, 3072)\n",
      "0.007486035214598104\n",
      "220\n",
      "(0.15812825193256072, 2.1153692443450014, 3072)\n",
      "0.007970221923579475\n",
      "230\n",
      "(0.15428390906385586, 2.1145020385837157, 3072)\n",
      "0.007444916831130394\n",
      "240\n",
      "(0.15745014802234913, 2.114789826236227, 3072)\n",
      "0.008260834469584595\n",
      "250\n",
      "(0.15363665243501368, 2.114292126262438, 3072)\n",
      "0.007850151960937041\n",
      "260\n",
      "(0.15826596515320826, 2.1151154790910445, 3072)\n",
      "0.007533775085159326\n",
      "270\n",
      "(0.15391268795172772, 2.1142083861682397, 3072)\n",
      "0.0078002372442612464\n",
      "280\n",
      "(0.15803372446959052, 2.115580093792034, 3072)\n",
      "0.0069709220879580775\n",
      "290\n",
      "(0.15648480313226185, 2.114582573427772, 3072)\n",
      "0.0074937980099752735\n",
      "300\n",
      "(0.16078362840146448, 2.1153318185891683, 3072)\n",
      "0.007575294541483539\n",
      "310\n",
      "(0.15769681442046757, 2.115100719329298, 3072)\n",
      "0.007701146796397674\n",
      "320\n",
      "(0.15544370774710484, 2.11447665565589, 3072)\n",
      "0.007291324660006034\n",
      "330\n",
      "(0.1532046842625833, 2.1139937877546853, 3072)\n",
      "0.007533609946557025\n",
      "340\n",
      "(0.1547118531551953, 2.114189261150013, 3072)\n",
      "0.007569959542029595\n",
      "350\n",
      "(0.15625367285008007, 2.1148140534667412, 3072)\n",
      "0.007303999107003847\n",
      "360\n",
      "(0.1505222523042708, 2.113567839427079, 3072)\n",
      "0.007348595640517047\n",
      "370\n",
      "(0.15638500712217485, 2.114529030532335, 3072)\n",
      "0.007741215648568839\n",
      "380\n",
      "(0.15480783417910243, 2.114381933903466, 3072)\n",
      "0.007512484212775461\n",
      "390\n",
      "(0.1547973692821162, 2.1147305393582663, 3072)\n",
      "0.007299386470848269\n",
      "400\n",
      "(0.15353835541380703, 2.1144563679617905, 3072)\n",
      "0.007281203311911981\n",
      "410\n",
      "(0.15506902050984012, 2.114233050675027, 3072)\n",
      "0.007748597606212273\n",
      "420\n",
      "(0.1512785342851371, 2.113784697275423, 3072)\n",
      "0.007251386789399131\n",
      "430\n",
      "(0.15197666109182117, 2.1139596824654125, 3072)\n",
      "0.007361159225611924\n",
      "440\n",
      "(0.15395132578686635, 2.1143095288592493, 3072)\n",
      "0.00732904678239826\n",
      "450\n",
      "(0.155602704635224, 2.1144083829574107, 3072)\n",
      "0.007627886628448848\n",
      "460\n",
      "(0.1527829512813088, 2.1140242249142447, 3072)\n",
      "0.007463298428648243\n",
      "470\n",
      "(0.15525351414555702, 2.1145766690112926, 3072)\n",
      "0.007243151068259307\n",
      "480\n",
      "(0.1546890869706792, 2.1142160593504453, 3072)\n",
      "0.007522642776055374\n",
      "490\n",
      "(0.14822214820772772, 2.1130843147906613, 3072)\n",
      "0.007599363991627021\n",
      "500\n",
      "(0.1546686393297546, 2.114312819899322, 3072)\n",
      "0.007256120566493126\n",
      "510\n",
      "(0.15315435359203794, 2.114001114239385, 3072)\n",
      "0.007000015102792384\n",
      "520\n",
      "(0.1531613593465353, 2.1138337160945895, 3072)\n",
      "0.007354147023659224\n",
      "530\n",
      "(0.15244340968810138, 2.113859748789282, 3072)\n",
      "0.007749223814316241\n",
      "540\n",
      "(0.15481793177537453, 2.1143342674984154, 3072)\n",
      "0.007886667576759872\n",
      "550\n",
      "(0.15363265955440664, 2.114458132818375, 3072)\n",
      "0.007761626456270315\n",
      "560\n",
      "(0.1528830715910853, 2.1140369553362923, 3072)\n",
      "0.007005789171236752\n",
      "570\n",
      "(0.1529694031056699, 2.1139537552068313, 3072)\n",
      "0.006858313000009761\n",
      "580\n",
      "(0.1494701825856115, 2.1131042415335926, 3072)\n",
      "0.0074378126045569586\n",
      "590\n",
      "(0.15533136851613807, 2.1144863234076254, 3072)\n",
      "0.006944259961018609\n",
      "600\n",
      "(0.14541966975252613, 2.1127167448176616, 3072)\n",
      "0.0073211937711267555\n",
      "610\n",
      "(0.15330095838572216, 2.114092364420804, 3072)\n",
      "0.007117198557583619\n",
      "620\n",
      "(0.15105498116219454, 2.1135945015521833, 3072)\n",
      "0.006892885774939221\n",
      "630\n",
      "(0.1541097874299164, 2.114222808358684, 3072)\n",
      "0.007648025500743166\n",
      "640\n",
      "(0.1485337777576539, 2.113153113787119, 3072)\n",
      "0.007243652671319024\n",
      "650\n",
      "(0.15101344586553342, 2.1139892283362602, 3072)\n",
      "0.0072995013531524395\n",
      "660\n",
      "(0.14830237583110775, 2.113058079099663, 3072)\n",
      "0.006935825956373342\n",
      "670\n",
      "(0.15308366356681904, 2.114102722002206, 3072)\n",
      "0.007322982934293332\n",
      "680\n",
      "(0.1525598932813381, 2.1136781822590827, 3072)\n",
      "0.007312669426716292\n",
      "690\n",
      "(0.15158222091762036, 2.1137202975296208, 3072)\n",
      "0.008338612472419892\n",
      "700\n",
      "(0.1482945782647519, 2.11317010424866, 3072)\n",
      "0.007769476593111185\n",
      "710\n",
      "(0.1507099159163999, 2.1137356560316727, 3072)\n",
      "0.0073095267620348825\n",
      "720\n",
      "(0.149161336129528, 2.1134833111475553, 3072)\n",
      "0.007184006906746703\n",
      "730\n",
      "(0.14283693886639795, 2.112133656228973, 3072)\n",
      "0.007096623814510296\n",
      "740\n",
      "(0.1520649492092692, 2.113680832367181, 3072)\n",
      "0.007687529282854418\n",
      "750\n",
      "(0.14931565719578682, 2.113323445198894, 3072)\n",
      "0.006541564074004117\n",
      "760\n",
      "(0.15409190500122008, 2.1141767525263706, 3072)\n",
      "0.007113075086118695\n",
      "770\n",
      "(0.1572616609067538, 2.1147870807618565, 3072)\n",
      "0.007638168239728962\n",
      "780\n",
      "(0.15383003315606475, 2.1143174932648288, 3072)\n",
      "0.006707200298272889\n",
      "790\n",
      "(0.1488273869699149, 2.1132436507095385, 3072)\n",
      "0.0069012210686818865\n",
      "800\n",
      "(0.1481845717127541, 2.113345950890533, 3072)\n",
      "0.006915750342683027\n",
      "810\n",
      "(0.15261206713549205, 2.1137080693300283, 3072)\n",
      "0.0076436712701001275\n",
      "820\n",
      "(0.15119414445801116, 2.113929659368415, 3072)\n",
      "0.007471977502367313\n",
      "830\n",
      "(0.15170708379093406, 2.113929569968177, 3072)\n",
      "0.0071408973684064635\n",
      "840\n",
      "(0.15467497743354774, 2.114345520566886, 3072)\n",
      "0.007553218094479734\n",
      "850\n",
      "(0.15152445437703346, 2.1137613833495896, 3072)\n",
      "0.007448643589787052\n",
      "860\n",
      "(0.15273079031871747, 2.1136704581370673, 3072)\n",
      "0.006963405625715831\n",
      "870\n",
      "(0.14652678007811093, 2.112719100109747, 3072)\n",
      "0.007357502637429231\n",
      "880\n",
      "(0.15262785051320274, 2.114098788523434, 3072)\n",
      "0.0072375769884511065\n",
      "890\n",
      "(0.1558956283903293, 2.114424306269272, 3072)\n",
      "0.007279247409003671\n",
      "900\n",
      "(0.15162528284804494, 2.1137892542720778, 3072)\n",
      "0.007042972793487452\n",
      "910\n",
      "(0.14807906000807425, 2.112933952034903, 3072)\n",
      "0.0072159896470080425\n",
      "920\n",
      "(0.14768608988782875, 2.1129515309509697, 3072)\n",
      "0.007258123064448172\n",
      "930\n",
      "(0.15278736750997315, 2.1136288922012882, 3072)\n",
      "0.007576729521370213\n",
      "940\n",
      "(0.15300401746671086, 2.11402010845638, 3072)\n",
      "0.00727438230513973\n",
      "950\n",
      "(0.14669257687977158, 2.113146354649047, 3072)\n",
      "0.006725701653200124\n",
      "960\n",
      "(0.14737505559062514, 2.113091321444019, 3072)\n",
      "0.007292624724956262\n",
      "970\n",
      "(0.1500101866724576, 2.1134502952238576, 3072)\n",
      "0.006918227943675255\n",
      "980\n",
      "(0.1521304059580038, 2.1137264011754913, 3072)\n",
      "0.007394918331815504\n",
      "990\n",
      "(0.15078940460024076, 2.1133426108282047, 3072)\n",
      "0.00713733678803607\n",
      "1000\n",
      "(0.14078271274546342, 2.1122417079660285, 3072)\n",
      "0.006626008242788552\n",
      "1010\n",
      "(0.15349958696256708, 2.114109491921138, 3072)\n",
      "0.007411463662803357\n",
      "1020\n",
      "(0.1489865703961776, 2.1132853762511554, 3072)\n",
      "0.007485378487448022\n",
      "1030\n",
      "(0.14931729367265262, 2.113441073008651, 3072)\n",
      "0.007075491458689287\n",
      "1040\n",
      "(0.14797230497315164, 2.1127822926009876, 3072)\n",
      "0.007012261623983853\n",
      "1050\n",
      "(0.15183815047121862, 2.113955424604429, 3072)\n",
      "0.007151143080982142\n",
      "1060\n",
      "(0.14332605156932307, 2.1121742120228455, 3072)\n",
      "0.007453572893353999\n",
      "1070\n",
      "(0.13826203820542565, 2.111215316656454, 3072)\n",
      "0.007495206666249253\n",
      "1080\n",
      "(0.1442104361611258, 2.1123376970003296, 3072)\n",
      "0.006979994288803712\n",
      "1090\n",
      "(0.14906268365827802, 2.1133421559133407, 3072)\n",
      "0.0068842950530489935\n",
      "1100\n",
      "(0.1515639961108737, 2.113658186933546, 3072)\n",
      "0.007067205895032553\n",
      "1110\n",
      "(0.14697997956300854, 2.1128747754096535, 3072)\n",
      "0.007378805724849962\n",
      "1120\n",
      "(0.14818262868182872, 2.1130860205306483, 3072)\n",
      "0.007145818326641102\n",
      "1130\n",
      "(0.14801754314437712, 2.113048039378349, 3072)\n",
      "0.007098349189454423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n",
      "(0.1498497547911642, 2.113323226730909, 3072)\n",
      "0.006894649474913816\n",
      "1150\n",
      "(0.14652969025552312, 2.112657318361886, 3072)\n",
      "0.007365240614149048\n",
      "1160\n",
      "(0.14749418858466232, 2.1131322655965747, 3072)\n",
      "0.0072614414486951735\n",
      "1170\n",
      "(0.15008432339798294, 2.1132095164060227, 3072)\n",
      "0.006943516118197643\n",
      "1180\n",
      "(0.1509056577580504, 2.113720315338605, 3072)\n",
      "0.007612405692538089\n",
      "1190\n",
      "(0.14907779888501424, 2.112991334720141, 3072)\n",
      "0.006818057298293839\n",
      "1200\n",
      "(0.1463161273722049, 2.1129691167314153, 3072)\n",
      "0.007244445584234932\n",
      "1210\n",
      "(0.14429417919231236, 2.1123063375481332, 3072)\n",
      "0.007030027559663528\n",
      "1220\n",
      "(0.14620762356321215, 2.1130062133989345, 3072)\n",
      "0.0073069066277726205\n",
      "1230\n",
      "(0.1441190527381024, 2.112661769753392, 3072)\n",
      "0.00758121512839299\n",
      "1240\n",
      "(0.145528665601993, 2.112529853216041, 3072)\n",
      "0.006852609795679608\n",
      "1250\n",
      "(0.14428020081705892, 2.11228533862334, 3072)\n",
      "0.006861423969064027\n",
      "1260\n",
      "(0.1427309010596827, 2.1124603546233236, 3072)\n",
      "0.0069012251051236975\n",
      "1270\n",
      "(0.14253651601553918, 2.1121522295595945, 3072)\n",
      "0.006804267579480471\n",
      "1280\n",
      "(0.147384664967117, 2.1129826471459277, 3072)\n",
      "0.007447308945069544\n",
      "1290\n",
      "(0.14896110997762374, 2.1135959710428263, 3072)\n",
      "0.0070058168787603585\n",
      "1300\n",
      "(0.14809253945255135, 2.113022170678819, 3072)\n",
      "0.006820503127479299\n",
      "1310\n",
      "(0.14347927445763226, 2.112566795016862, 3072)\n",
      "0.007336544075186041\n",
      "1320\n",
      "(0.14326523323319587, 2.112301437816309, 3072)\n",
      "0.006961482073307496\n",
      "1330\n",
      "(0.14208150044640674, 2.1121980964610327, 3072)\n",
      "0.006935942495673124\n",
      "1340\n",
      "(0.1455855822513559, 2.1125606281211953, 3072)\n",
      "0.007147895161420892\n",
      "1350\n",
      "(0.14612116676850975, 2.1124109575058414, 3072)\n",
      "0.006892302434428822\n",
      "1360\n",
      "(0.1457242205662982, 2.1130555679497864, 3072)\n",
      "0.006829804842474967\n",
      "1370\n",
      "(0.14531271301001247, 2.1127206498359055, 3072)\n",
      "0.0073277553917601105\n",
      "1380\n",
      "(0.14184932552817944, 2.1120688016691522, 3072)\n",
      "0.006914924606105991\n",
      "1390\n",
      "(0.14417261278739074, 2.112438989085326, 3072)\n",
      "0.006520418796355433\n",
      "1400\n",
      "(0.14611054692382885, 2.1125420628791076, 3072)\n",
      "0.007127443943144554\n",
      "1410\n",
      "(0.14223015282088688, 2.1121821515498045, 3072)\n",
      "0.007050327392314431\n",
      "1420\n",
      "(0.14669452042830122, 2.1125387947962366, 3072)\n",
      "0.007131356117163958\n",
      "1430\n",
      "(0.14196554164410863, 2.1120260439669125, 3072)\n",
      "0.007385147570156218\n",
      "1440\n",
      "(0.14981105461111976, 2.1134701261631976, 3072)\n",
      "0.007329377349830311\n",
      "1450\n",
      "(0.14670743981066142, 2.1127791772950535, 3072)\n",
      "0.00694377454754408\n",
      "1460\n",
      "(0.1473295127270921, 2.112885411940697, 3072)\n",
      "0.007101918210133597\n",
      "1470\n",
      "(0.1486402047264578, 2.113159602146418, 3072)\n",
      "0.0070324172620055015\n",
      "1480\n",
      "(0.14539911864481467, 2.112551565957596, 3072)\n",
      "0.006865501721486493\n",
      "1490\n",
      "(0.1456840007364237, 2.11267593622901, 3072)\n",
      "0.007284404181429077\n",
      "1500\n",
      "(0.14273242572589548, 2.112196133464854, 3072)\n",
      "0.007055556731189397\n",
      "1510\n",
      "(0.14372048856203853, 2.1124985374600396, 3072)\n",
      "0.0072520304078498\n",
      "1520\n",
      "(0.14475812287388365, 2.1125559330925556, 3072)\n",
      "0.006530004712362239\n",
      "1530\n",
      "(0.14684076708137261, 2.11326435823003, 3072)\n",
      "0.007218291564874498\n",
      "1540\n",
      "(0.14232455994657034, 2.1121528847623563, 3072)\n",
      "0.006695920453311466\n",
      "1550\n",
      "(0.14846806854058892, 2.113402304230399, 3072)\n",
      "0.007014638168150563\n",
      "1560\n",
      "(0.14689257451574755, 2.1128305929219886, 3072)\n",
      "0.007071984062205275\n",
      "1570\n",
      "(0.14263436097521387, 2.112055862996576, 3072)\n",
      "0.007041596654490038\n",
      "1580\n",
      "(0.14262545327738646, 2.1121613164027426, 3072)\n",
      "0.007002880613249941\n",
      "1590\n",
      "(0.14967529671805418, 2.113460155352803, 3072)\n",
      "0.0064614510502956695\n",
      "1600\n",
      "(0.1444182092466478, 2.112242042567734, 3072)\n",
      "0.007309956693160646\n",
      "1610\n",
      "(0.14844312680214872, 2.1132730209441357, 3072)\n",
      "0.007033818978628809\n",
      "1620\n",
      "(0.14701183133208703, 2.1129950094635563, 3072)\n",
      "0.007288248434979957\n",
      "1630\n",
      "(0.14503077950436025, 2.112232497902721, 3072)\n",
      "0.007013040851477001\n",
      "1640\n",
      "(0.14946314226631852, 2.1131989689461776, 3072)\n",
      "0.007866862681184276\n",
      "1650\n",
      "(0.14058710240047834, 2.111697383368957, 3072)\n",
      "0.0074263042640707105\n",
      "1660\n",
      "(0.14725404843354492, 2.1128979577930593, 3072)\n",
      "0.007104357831555627\n",
      "1670\n",
      "(0.14379662889167255, 2.1123749046925737, 3072)\n",
      "0.007086300140933844\n",
      "1680\n",
      "(0.14510098984458714, 2.1126523113573334, 3072)\n",
      "0.006844276144521259\n",
      "1690\n",
      "(0.14346019908360105, 2.1124537338850353, 3072)\n",
      "0.006890534995338089\n",
      "1700\n",
      "(0.14840746012115885, 2.1133805967409596, 3072)\n",
      "0.007020600071872949\n",
      "1710\n",
      "(0.14115589082221006, 2.111876258658628, 3072)\n",
      "0.006765407026867784\n",
      "1720\n",
      "(0.14643918082588295, 2.112868034349249, 3072)\n",
      "0.007051850699058011\n",
      "1730\n",
      "(0.14648696768417294, 2.112725137921603, 3072)\n",
      "0.007214086110427586\n",
      "1740\n",
      "(0.14608655596113362, 2.1124538976702016, 3072)\n",
      "0.006768817753203199\n",
      "1750\n",
      "(0.1433261762692629, 2.1120196742654955, 3072)\n",
      "0.0073252393078339\n",
      "1760\n",
      "(0.13982014535276213, 2.111618542149975, 3072)\n",
      "0.006844510577059931\n",
      "1770\n",
      "(0.14465999892809978, 2.1127756297337883, 3072)\n",
      "0.006727210387936904\n",
      "1780\n",
      "(0.14070350724430172, 2.11162104613818, 3072)\n",
      "0.00643435738617003\n",
      "1790\n",
      "(0.1451362245009555, 2.112607569954426, 3072)\n",
      "0.007202098168684155\n",
      "1800\n",
      "(0.1440298145780806, 2.1125121160402256, 3072)\n",
      "0.007012741009073061\n",
      "1810\n",
      "(0.14036494244965966, 2.111502422590145, 3072)\n",
      "0.006768136504368467\n",
      "1820\n",
      "(0.15104173177208902, 2.1137168957024555, 3072)\n",
      "0.006695660173483652\n",
      "1830\n",
      "(0.14665869357015462, 2.112614665924376, 3072)\n",
      "0.007115814743516913\n",
      "1840\n",
      "(0.14094289670479387, 2.111809900462774, 3072)\n",
      "0.0063680891887633205\n",
      "1850\n",
      "(0.14379570005931303, 2.1122642223690034, 3072)\n",
      "0.006930040309965037\n",
      "1860\n",
      "(0.1429209766371327, 2.1124205535143696, 3072)\n",
      "0.0070842172386203885\n",
      "1870\n",
      "(0.14957174407588153, 2.1133684791547114, 3072)\n",
      "0.007178420656862466\n",
      "1880\n",
      "(0.14627904251225005, 2.112928908489078, 3072)\n",
      "0.007059625874885019\n",
      "1890\n",
      "(0.14387010137052722, 2.1125214181246417, 3072)\n",
      "0.007215333079287446\n",
      "1900\n",
      "(0.14573293906427726, 2.11311517209687, 3072)\n",
      "0.00654171714020959\n",
      "1910\n",
      "(0.1453526604973565, 2.1125723141996553, 3072)\n",
      "0.006905424180097146\n",
      "1920\n",
      "(0.1422297510324425, 2.1121795622522352, 3072)\n",
      "0.006254128332247215\n",
      "1930\n",
      "(0.14494157960392562, 2.1127126418322653, 3072)\n",
      "0.0071191946308786554\n",
      "1940\n",
      "(0.13968543359172164, 2.1118751641212117, 3072)\n",
      "0.006444455400228037\n",
      "1950\n",
      "(0.14251303624343242, 2.1120720773784005, 3072)\n",
      "0.006980204607044804\n",
      "1960\n",
      "(0.1379388149924453, 2.111354102867186, 3072)\n",
      "0.006722096851723945\n",
      "1970\n",
      "(0.14324552505122737, 2.112575288313341, 3072)\n",
      "0.007220294870377099\n",
      "1980\n",
      "(0.1392266680884321, 2.1116009648797056, 3072)\n",
      "0.006800284052070908\n",
      "1990\n",
      "(0.13700821519389064, 2.1117880904499517, 3072)\n",
      "0.007506633734697158\n",
      "2000\n",
      "(0.14466085281694174, 2.1126696687185262, 3072)\n",
      "0.0068602675835898646\n",
      "2010\n",
      "(0.14671720422038836, 2.1130383820149494, 3072)\n",
      "0.007175238877229099\n",
      "2020\n",
      "(0.14267002448472452, 2.1119689449999752, 3072)\n",
      "0.007038278742150148\n",
      "2030\n",
      "(0.14006458064514601, 2.111755305471324, 3072)\n",
      "0.007137444337364155\n",
      "2040\n",
      "(0.14192589087932841, 2.1121477973505702, 3072)\n",
      "0.007235697460013351\n",
      "2050\n",
      "(0.14072864015994974, 2.111766274501154, 3072)\n",
      "0.006419617736421965\n",
      "2060\n",
      "(0.14185282631808888, 2.112011424242547, 3072)\n",
      "0.007155609610252987\n",
      "2070\n",
      "(0.1388217889733827, 2.111674106182289, 3072)\n",
      "0.006505377328658847\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-585b24754a04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mGradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mIndexing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morthogonal_mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mData_Patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mSparsity_Loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData_Patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPhi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mSparse_Rep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\omp.pyc\u001b[0m in \u001b[0;36morthogonal_mp\u001b[1;34m(X, y, n_nonzero_coefs, tol, precompute, copy_X, return_path, return_n_iter)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     \"\"\"\n\u001b[1;32m--> 344\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[0mcopy_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# false positives from overflow in sum method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n\u001b[0m\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n",
      "\u001b[1;32mC:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\envs\\py2\\lib\\site-packages\\numpy\\core\\_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SGD Loop to update Dictionary\n",
    "Data_Patches = Data_Patches\n",
    "mini_batch_size = 512\n",
    "tol = 10**(-32)\n",
    "max_iterations = 100000\n",
    "eta =.0001 #Learning Rate (Lower is better)\n",
    "lam = .35 #found through orthogonal feature reconstructions above\n",
    "lam_vector = np.full((len(Phi.T), 1), lam, dtype=np.float)\n",
    "count = 0\n",
    "Previous_Gradient = 0\n",
    "momentum_term = .9\n",
    "\n",
    "\n",
    "\n",
    "Total_Energies = []\n",
    "Total_Recon_Loss = []\n",
    "Non_Zero_Coefficients =[] #Helps see how sparse reconstructions are while learning\n",
    "eta_initial =.01\n",
    "eta_final = .000001#Learning Rate (Lower is better)\n",
    "eta = eta_initial\n",
    "for iteration in range(max_iterations):\n",
    "    \n",
    "        \n",
    "    #Random Draw from Data\n",
    "    Indexing = random.sample(range(len(Data_Patches)), mini_batch_size)\n",
    "    \n",
    "    Neuron_Activation =[]\n",
    "    Gradients =[]\n",
    "    Unembedded_Solutions_Training= []\n",
    "    t1 = time.time()\n",
    "    New_Solutions = []\n",
    "    Temp_Data_Patches=[]\n",
    "    Q = .5*np.dot(np.squeeze(Phi.T),np.squeeze(Phi))\n",
    "    \n",
    "\n",
    "\n",
    "    image_number = 0\n",
    "    Sparse_Rep=[]\n",
    "    Loss = []\n",
    "    Sparsity_Loss = []\n",
    "    Gradients = []\n",
    "    for sample in Indexing:\n",
    "        temp = orthogonal_mp(Phi,Data_Patches[sample])\n",
    "        Sparsity_Loss.append((sparse_loss(Data_Patches[sample],Phi,temp.T,lam)))\n",
    "        Sparse_Rep.append(temp)\n",
    "        Loss.append(LA.norm(Data_Patches[sample]-np.dot(Phi,orthogonal_mp(Phi,Data_Patches[sample]))))\n",
    "        error = np.subtract(Data_Patches[sample].T,np.squeeze(np.dot(Phi,temp.T)))\n",
    "        Delta_Phi =np.outer(error,temp)\n",
    "        Delta_Phi = np.asarray(Delta_Phi)\n",
    "        Gradients.append(Delta_Phi)\n",
    "        \n",
    "    Gradient = sum(np.asarray(Gradients))/mini_batch_size\n",
    "    #print(Gradient.shape)\n",
    "    #Phi_New = Phi - (eta/mini_batch_size)*np.squeeze(Delta_Phi).T + momentum_term*Previous_Gradient\n",
    "    Phi_New = Phi - (eta)*Gradient + momentum_term*Previous_Gradient #non division by mini batch size\n",
    "    Previous_Gradient = Gradient\n",
    "    \n",
    "    for i in range(Neurons):\n",
    "        Phi_New[:,i]= Phi_New[:,i]/(math.sqrt(np.dot(Phi_New[:,i].T,Phi_New[:,i])))\n",
    "    Previous_Gradient = Gradient \n",
    "\n",
    "    Loss = sum(np.asarray(Loss))/len(Indexing)\n",
    "    Sparsity_Loss = sum(np.asarray(Sparsity_Loss))/len(Indexing)\n",
    "    Total_Energies.append(Sparsity_Loss)\n",
    "    Total_Recon_Loss.append(Loss)\n",
    "\n",
    "#\n",
    "    \n",
    "    if count%10==0:\n",
    "        print(count)\n",
    "        print(Loss,Sparsity_Loss,np.count_nonzero(Sparse_Rep))\n",
    "        print(LA.norm(Phi_New-Phi))\n",
    "    #print(plt.plot(range(iteration+1), Total_Energies ))\n",
    "    #print('Energies,Epoc :', Total_Energies,count)\n",
    "    elapsed1 = time.time() - t1\n",
    "    #print(elapsed1)\n",
    "    count += 1\n",
    "\n",
    "#     sio.savemat('Phi_New_Fashion_MiniBatch1000_sPCA_AFRL_32_Lambda_'+str(lam)+'_OMP.mat', {'Phi_New':Phi_New})\n",
    "#     sio.savemat('TotalEnergies_Fashion_MiniBatch1000_sPCA_AFRL_32_Lambda_'+str(lam)+'_OMP.mat', {'Total_Energies':Total_Energies})\n",
    "    if LA.norm(Phi_New-Phi) > tol:\n",
    "        #print(LA.norm(Phi_New-Phi))\n",
    "        Phi = Phi_New\n",
    "        eta = eta_initial*((eta_final/float(eta_initial))**(iteration/float(max_iterations))) #exponentially decaying learing rate\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('converged')\n",
    "        \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('AFRL_Recon_Patches', Data_Patches)\n",
    "np.save('Phi_Recon_OMP', Phi_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
