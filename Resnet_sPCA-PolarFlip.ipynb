{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import MaxPooling2D, AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import ortho_group\n",
    "from sklearn.svm import SVC \n",
    "import math \n",
    "import random\n",
    "from numpy import linalg as LA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import orthogonal_mp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/LANL/AFRL-DISC Data/Blackbox brief for LANL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary spca components\n",
    "#Load sPCA Dictionary from found sPCA components\n",
    "mat = sio.loadmat('sPCA_Phi.mat')\n",
    "sPCA_Phi = mat['sPCA_Phi']\n",
    "\n",
    "sPCA= pd.read_csv('sPCA_32.csv', sep=',', encoding = 'utf8')\n",
    "data = sPCA.values\n",
    "data= np.dot(data,sPCA_Phi)\n",
    "\n",
    "# data = np.load('Repatched_Dwave_Data_7x7.npy')\n",
    "# data = data.reshape(len(data),28*28)\n",
    "# mat = sio.loadmat('data_binned.mat')\n",
    "# data_binned = np.asarray(mat['data_binned'])\n",
    "# data_binned = np.dot(data_binned,sPCA_Phi)\n",
    "#data_binned = np.reshape(len(data_binned),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = sio.loadmat('fMnist_ytrainlabels.mat')\n",
    "Y_train = np.squeeze(np.asarray(mat['y_train'].T))\n",
    "mat = sio.loadmat('fMnist_ytestlabels.mat')\n",
    "Y_test = np.squeeze(np.asarray(mat['y_test'].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[0:len(Y_train)]\n",
    "X_test = data[len(Y_train):len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reshape(len(data),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data*(-1)\n",
    "data1 = data1.reshape(len(data1),28,28)\n",
    "data = data.reshape(len(data),28,28)\n",
    "X_train = data[0:len(Y_train)]\n",
    "X_test = data[len(Y_train):len(data)]\n",
    "X_train1 = data1[0:len(Y_train)]\n",
    "X_test1 = data1[len(Y_train):len(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = np.concatenate((X_train,X_train1))\n",
    "X_test_final = np.concatenate((X_test,X_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train1 = Y_train\n",
    "Y_test1 = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate((Y_train,Y_train1))\n",
    "Y_test = np.concatenate((Y_test,Y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 28, 28) (120000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = X_train_final\n",
    "X_test = X_test_final\n",
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('fMNIST_Training_Labels',Y_train)\n",
    "np.save('fMNIST_Test_Labels',Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train),28*28)\n",
    "X_test = X_test.reshape(len(X_test),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7724"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Random Forest Reference Solution\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth = 10, random_state = 1)\n",
    "clf.fit(X_train,Y_train)\n",
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_final\n",
    "X_test = X_test_final\n",
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 5, 10000, 10001, 10003, 10005]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets visualize few images \n",
    "sample = np.random.randint(0,high= 59999, size=8)\n",
    "sample = [0,1,3,5,10000,10001,10003, 10005]\n",
    "print(sample)\n",
    "sample_img = X_test[sample, :]\n",
    "sample_label = Y_test[sample]\n",
    "for i , img in enumerate(sample_img):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(sample_label[i])\n",
    "    img = img.reshape(28,28)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining constants\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "data_augmentation = False\n",
    "img_size = 28\n",
    "\n",
    "num_classes = 10\n",
    "num_filters = 64\n",
    "num_blocks = 4\n",
    "num_sub_blocks = 2\n",
    "use_max_pool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (120000, 28, 28, 1)\n",
      "120000 train samples\n",
      "20000 test samples\n",
      "Y_train shape: (120000,)\n"
     ]
    }
   ],
   "source": [
    "x_train = X_train.reshape(X_train.shape[0],img_size,img_size,1)\n",
    "x_test = X_test.reshape(X_test.shape[0],img_size,img_size,1)\n",
    "input_size = (img_size, img_size,1)\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "\n",
    "#Converting labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 14, 14, 64)   3200        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 14, 14, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 14, 14, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 14, 14, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 14, 14, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 14, 14, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 14, 14, 64)   0           activation_1[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 14, 14, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 14, 14, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 14, 14, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 14, 14, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 14, 14, 64)   0           activation_3[0][0]               \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 14, 14, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 128)    73856       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 128)    512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 128)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 128)    147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 128)    8320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 128)    512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 7, 7, 128)    0           conv2d_8[0][0]                   \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 128)    147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 128)    512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 128)    147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 7, 128)    512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 7, 7, 128)    0           activation_7[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 4, 4, 256)    295168      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 256)    1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 4, 4, 256)    590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 256)    33024       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 256)    0           conv2d_13[0][0]                  \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 256)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 256)    590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 256)    1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 256)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 256)    590080      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 256)    1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 256)    0           activation_11[0][0]              \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 256)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 2, 2, 512)    1180160     activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2, 2, 512)    2048        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2, 2, 512)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 512)    2359808     activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 2, 2, 512)    131584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 2, 512)    2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 512)    0           conv2d_18[0][0]                  \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 2, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 2, 2, 512)    2359808     activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2, 2, 512)    2048        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2, 2, 512)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 2, 2, 512)    2359808     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 2, 2, 512)    2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 512)    0           activation_15[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2, 2, 512)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 1, 1, 512)    0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           5130        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Creating model based on ResNet published archietecture\n",
    "inputs = Input(shape=input_size)\n",
    "x = Conv2D(num_filters, padding='same', \n",
    "           kernel_initializer='he_normal', \n",
    "           kernel_size=7, strides=2,\n",
    "           kernel_regularizer=l2(1e-4))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "#Check by applying max pooling later (setting it false as size of image is small i.e. 28x28)\n",
    "if use_max_pool:\n",
    "    x = MaxPooling2D(pool_size=3,padding='same', strides=2)(x)\n",
    "    num_blocks =3\n",
    "#Creating Conv base stack \n",
    "\n",
    "# Instantiate convolutional base (stack of blocks).\n",
    "for i in range(num_blocks):\n",
    "    for j in range(num_sub_blocks):\n",
    "        strides = 1\n",
    "        is_first_layer_but_not_first_block = j == 0 and i > 0\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            strides = 2\n",
    "        #Creating residual mapping using y\n",
    "        y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   strides=strides,\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(x)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(num_filters,\n",
    "                   kernel_size=3,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='he_normal',\n",
    "                   kernel_regularizer=l2(1e-4))(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        if is_first_layer_but_not_first_block:\n",
    "            x = Conv2D(num_filters,\n",
    "                       kernel_size=1,\n",
    "                       padding='same',\n",
    "                       strides=2,\n",
    "                       kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=l2(1e-4))(x)\n",
    "        #Adding back residual mapping\n",
    "        x = keras.layers.add([x, y])\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    num_filters = 2 * num_filters\n",
    "\n",
    "# Add classifier on top.\n",
    "x = AveragePooling2D()(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(num_classes,\n",
    "                activation='softmax',\n",
    "                kernel_initializer='he_normal')(y)\n",
    "\n",
    "# Instantiate and compile model.\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(os.getcwd(), 'saved_model')\n",
    "model_name = 'fmnist_resnet_model_sPCA_Polar.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir,model_name)\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare callbacks for model saving and for learning rate decaying.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "callbacks = [checkpoint, lr_reducer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using data augmentation.\n",
      "WARNING:tensorflow:From C:\\Users\\khenk\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 120000 samples, validate on 20000 samples\n",
      "Epoch 1/30\n",
      "120000/120000 [==============================] - 6539s 54ms/step - loss: 1.1327 - acc: 0.8266 - val_loss: 14.9119 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 14.91191, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 2/30\n",
      "120000/120000 [==============================] - 6823s 57ms/step - loss: 0.6708 - acc: 0.8672 - val_loss: 10.8773 - val_acc: 0.1121\n",
      "\n",
      "Epoch 00002: val_loss improved from 14.91191 to 10.87732, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 3/30\n",
      "120000/120000 [==============================] - 6851s 57ms/step - loss: 0.5470 - acc: 0.8784 - val_loss: 2.2770 - val_acc: 0.3235\n",
      "\n",
      "Epoch 00003: val_loss improved from 10.87732 to 2.27699, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 4/30\n",
      "120000/120000 [==============================] - 6919s 58ms/step - loss: 0.5399 - acc: 0.8800 - val_loss: 14.6977 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.27699\n",
      "Epoch 5/30\n",
      "120000/120000 [==============================] - 6697s 56ms/step - loss: 0.4564 - acc: 0.8910 - val_loss: 14.6608 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.27699\n",
      "Epoch 6/30\n",
      "120000/120000 [==============================] - 6705s 56ms/step - loss: 0.4884 - acc: 0.8911 - val_loss: 6.6344 - val_acc: 0.1378\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.27699\n",
      "Epoch 7/30\n",
      "120000/120000 [==============================] - 6804s 57ms/step - loss: 0.8592 - acc: 0.8388 - val_loss: 3.2592 - val_acc: 0.3219\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.27699\n",
      "Epoch 8/30\n",
      "120000/120000 [==============================] - 6857s 57ms/step - loss: 0.6608 - acc: 0.8817 - val_loss: 1.6988 - val_acc: 0.5423\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.27699 to 1.69884, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 9/30\n",
      "120000/120000 [==============================] - 7001s 58ms/step - loss: 0.5637 - acc: 0.8963 - val_loss: 1.4703 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.69884 to 1.47032, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 10/30\n",
      "120000/120000 [==============================] - 7107s 59ms/step - loss: 0.5054 - acc: 0.9039 - val_loss: 6.5928 - val_acc: 0.1892\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.47032\n",
      "Epoch 11/30\n",
      "120000/120000 [==============================] - 7065s 59ms/step - loss: 0.4858 - acc: 0.9077 - val_loss: 1.2229 - val_acc: 0.6596\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.47032 to 1.22286, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 12/30\n",
      "120000/120000 [==============================] - 7012s 58ms/step - loss: 0.4422 - acc: 0.9126 - val_loss: 2.2398 - val_acc: 0.2939\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.22286\n",
      "Epoch 13/30\n",
      "120000/120000 [==============================] - 7014s 58ms/step - loss: 0.4057 - acc: 0.9177 - val_loss: 12.7869 - val_acc: 0.1061\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.22286\n",
      "Epoch 14/30\n",
      "120000/120000 [==============================] - 7525s 63ms/step - loss: 0.3880 - acc: 0.9199 - val_loss: 3.3724 - val_acc: 0.1520\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.22286\n",
      "Epoch 15/30\n",
      "120000/120000 [==============================] - 7484s 62ms/step - loss: 0.3813 - acc: 0.9221 - val_loss: 14.7071 - val_acc: 0.1000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.22286\n",
      "Epoch 16/30\n",
      "120000/120000 [==============================] - 7143s 60ms/step - loss: 0.3819 - acc: 0.9233 - val_loss: 6.7877 - val_acc: 0.1103\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.22286\n",
      "Epoch 17/30\n",
      "120000/120000 [==============================] - 6943s 58ms/step - loss: 0.2835 - acc: 0.9544 - val_loss: 0.6797 - val_acc: 0.8273\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.22286 to 0.67971, saving model to C:\\Users\\khenk\\Desktop\\LANL\\AFRL-DISC Data\\Blackbox brief for LANL\\saved_model\\fmnist_resnet_model_sPCA_Polar.h5\n",
      "Epoch 18/30\n",
      "120000/120000 [==============================] - 6892s 57ms/step - loss: 0.2260 - acc: 0.9685 - val_loss: 0.9755 - val_acc: 0.7565\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.67971\n",
      "Epoch 19/30\n",
      "120000/120000 [==============================] - 6894s 57ms/step - loss: 0.1950 - acc: 0.9755 - val_loss: 1.0417 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.67971\n",
      "Epoch 20/30\n",
      "120000/120000 [==============================] - 7349s 61ms/step - loss: 0.1807 - acc: 0.9794 - val_loss: 2.7007 - val_acc: 0.3735\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.67971\n",
      "Epoch 21/30\n",
      "120000/120000 [==============================] - 7801s 65ms/step - loss: 0.1723 - acc: 0.9817 - val_loss: 0.9610 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.67971\n",
      "Epoch 22/30\n",
      "120000/120000 [==============================] - 7144s 60ms/step - loss: 0.1559 - acc: 0.9846 - val_loss: 0.9772 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.67971\n",
      "Epoch 23/30\n",
      "120000/120000 [==============================] - 7205s 60ms/step - loss: 0.1217 - acc: 0.9965 - val_loss: 0.7757 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.67971\n",
      "Epoch 24/30\n",
      "120000/120000 [==============================] - 7358s 61ms/step - loss: 0.1086 - acc: 0.9986 - val_loss: 0.8330 - val_acc: 0.8744\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.67971\n",
      "Epoch 25/30\n",
      "120000/120000 [==============================] - 7225s 60ms/step - loss: 0.1038 - acc: 0.9982 - val_loss: 0.8461 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.67971\n",
      "Epoch 26/30\n",
      "120000/120000 [==============================] - 7168s 60ms/step - loss: 0.0974 - acc: 0.9987 - val_loss: 0.8375 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.67971\n",
      "Epoch 27/30\n",
      "120000/120000 [==============================] - 7131s 59ms/step - loss: 0.0931 - acc: 0.9984 - val_loss: 0.9022 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.67971\n",
      "Epoch 28/30\n",
      "120000/120000 [==============================] - 6954s 58ms/step - loss: 0.0863 - acc: 0.9996 - val_loss: 0.9480 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.67971\n",
      "Epoch 29/30\n",
      "120000/120000 [==============================] - 6845s 57ms/step - loss: 0.0827 - acc: 1.0000 - val_loss: 1.0517 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.67971\n",
      "Epoch 30/30\n",
      "120000/120000 [==============================] - 6897s 57ms/step - loss: 0.0801 - acc: 0.9999 - val_loss: 0.9934 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.67971\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=30,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 129s 6ms/step\n",
      "Test loss: 0.993353442955017\n",
      "Test accuracy: 0.88325\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
